{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning a Transformer model based on coonversation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: This is just a simple implementation of how one could approach to such an idea, the results might not be too astonishing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4vRJ7mzqixR"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install sentencepiece\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dataframe from the conversation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8JrzVkaFqlM4"
   },
   "outputs": [],
   "source": [
    "data = load_dataset(\"multi_woz_v22\")\n",
    "customer = []\n",
    "server = []\n",
    "for dialogues in data['train']['turns']:\n",
    "    for i in range(len(dialogues['utterance'])):\n",
    "    if i%2 ==0:\n",
    "        customer.append(dialogues['utterance'][i])\n",
    "    else:\n",
    "        server.append(dialogues['utterance'][i])\n",
    "\n",
    "df = pd.DataFrame({\"question\":customer,\"answer\":server})\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wRPfLX6mqlIA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "994iqfSHpL7A"
   },
   "source": [
    "# The dataset contains a conversation between customers and our support agents, we are going to train our model on this conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 733
    },
    "id": "JzhDXk-BqlGD",
    "outputId": "19266368-6c5f-403d-d901-d6881873d06e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-38bad647-c059-4078-9560-ffc25cc11280\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19498</th>\n",
       "      <td>I need to book a train for Friday please.</td>\n",
       "      <td>Great. Where are you headed?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25916</th>\n",
       "      <td>if there ain't none, can you try a nightclub? ...</td>\n",
       "      <td>The place is a nightclub in the south.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26109</th>\n",
       "      <td>Can you select one of the restaurants with the...</td>\n",
       "      <td>The dojo noodle house would be an option for you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50373</th>\n",
       "      <td>Ok, thank you.</td>\n",
       "      <td>Is there anything else I can help you with?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5329</th>\n",
       "      <td>I want to go to ely and arrive by 11:15.</td>\n",
       "      <td>I'm sorry for the confusion, just to verify-ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54343</th>\n",
       "      <td>No. Just pick something and give me the address.</td>\n",
       "      <td>Okay. I recommend Churchill College at Storey'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38158</th>\n",
       "      <td>I would like to reserve it for 11:15 for 8 peo...</td>\n",
       "      <td>Booking was successful. The table will be rese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>I am leaving peterborough.</td>\n",
       "      <td>What time do you need to travel?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>No. That's everything I needed and then some, ...</td>\n",
       "      <td>Thank you for calling. Have a great day!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56422</th>\n",
       "      <td>That would be perfect. Can I get the phone num...</td>\n",
       "      <td>Yes. Their phone number is 01223314960. Can I ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45420 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38bad647-c059-4078-9560-ffc25cc11280')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-38bad647-c059-4078-9560-ffc25cc11280 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-38bad647-c059-4078-9560-ffc25cc11280');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                question  \\\n",
       "19498          I need to book a train for Friday please.   \n",
       "25916  if there ain't none, can you try a nightclub? ...   \n",
       "26109  Can you select one of the restaurants with the...   \n",
       "50373                                     Ok, thank you.   \n",
       "5329            I want to go to ely and arrive by 11:15.   \n",
       "...                                                  ...   \n",
       "54343   No. Just pick something and give me the address.   \n",
       "38158  I would like to reserve it for 11:15 for 8 peo...   \n",
       "860                           I am leaving peterborough.   \n",
       "15795  No. That's everything I needed and then some, ...   \n",
       "56422  That would be perfect. Can I get the phone num...   \n",
       "\n",
       "                                                  answer  \n",
       "19498                       Great. Where are you headed?  \n",
       "25916             The place is a nightclub in the south.  \n",
       "26109   The dojo noodle house would be an option for you  \n",
       "50373        Is there anything else I can help you with?  \n",
       "5329   I'm sorry for the confusion, just to verify-ar...  \n",
       "...                                                  ...  \n",
       "54343  Okay. I recommend Churchill College at Storey'...  \n",
       "38158  Booking was successful. The table will be rese...  \n",
       "860                     What time do you need to travel?  \n",
       "15795           Thank you for calling. Have a great day!  \n",
       "56422  Yes. Their phone number is 01223314960. Can I ...  \n",
       "\n",
       "[45420 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: total number of rows (45420) exceeds max_rows (20000). Limiting to first (20000) rows.\n"
     ]
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lbMmDaf6pIyj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQ0ZrlVjiJJA"
   },
   "source": [
    "## Defining Tokenizer\n",
    "#### We are using a pretrained GPT2 tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e6iOcjAlnCE8"
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "tokenizer.add_special_tokens({'bos_token': '[start]', 'eos_token': '[end]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "frV2PqEqirzg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pZPJqsqZirxP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZSg7HC7jm43"
   },
   "source": [
    "## Defining Custom Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things that are required by the gpt2 model (or any other transformer based model) are input_ids (tokenized sentences), attention_mask and labels, all of which is defined in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RxL4_e9wjl93"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, tokenizer, data):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_length = 150\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        question = row['question']\n",
    "        answer = row['answer']\n",
    "        q_and_a = f'[start]{question}[end]{answer}'\n",
    "        encoding = self.tokenizer(question,answer,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        input_ids = encoding['input_ids'].squeeze()\n",
    "        attention_mask= encoding['attention_mask'].squeeze()\n",
    "        \n",
    "        item = {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "        }\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YqebP4l6m0Sk"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "@torch.no_grad()\n",
    "def validate(model, tokenizer,val_dl):\n",
    "    model.eval()\n",
    "    # tokenized = tokenizer(prompt, return_tensors='pt')\n",
    "    for step, batch in enumerate(val_dl):\n",
    "        if step==4:\n",
    "            break\n",
    "        inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "        sample_output = model.generate(**inputs, do_sample=True, max_length=100, top_k=20, top_p=1.0)\n",
    "        generated_text = tokenizer.decode(sample_output[0], skip_special_tokens=True)\n",
    "        print(f' This is Generated Text----------------> {generated_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated text output is showing as a single letter here because an error I made earlier, I only showed the first letter of the generated text, I did not rerun the cell because it was taking a lot of time on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "c85dfb2b4f0b40bc9e7fa136d4d687ac",
      "4d9f5d90cb454f0592bba9c9613e3ce2",
      "c35f1bee65d04727970442cf3b599fd4",
      "9205efdc3e714349ac0e5e36ba0d83dd",
      "f48cc60833d64180b24c8d8a5bffd586",
      "8e8e01529dc941c9bf57cb3eae654952",
      "9d01468b3d8048188096e7005ac89a1e",
      "83edce4e80bc47c2a28f8e2eaeeaf08e",
      "5ab5d2c0724646fda38f43227d719ade",
      "a1e2d74f9b1e41d8903d08dc385e513e",
      "f18a9f7e9ba24fde8cd1fa4449466e34",
      "9daece72701d40c79c2c8de34a09aa2a",
      "af713c9c41f742e7b0b21417c49ef2ce",
      "cea7d027cf6c4550b2a30a761655e754",
      "2aeeaaaed9624e60907c221c4daccbdd",
      "e0adcab743004f19893397a6132df2c6",
      "97a4f1d1434945d0ab01136af628f009",
      "4a2679e2032c4889a9e7c4043c2b9828",
      "25488d0f2abd4ca988c899ff347ab6b8",
      "3728fe249c8140cebcc54801f3ab2cd5",
      "7a0abe88007344a080049fce14f5e9ca",
      "4aabdd76e5c24520967107cd0c5fb519"
     ]
    },
    "id": "OXVqwfoKROJP",
    "outputId": "0adc82b9-74d0-4427-dcdb-bd14362ac022"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c85dfb2b4f0b40bc9e7fa136d4d687ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9daece72701d40c79c2c8de34a09aa2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100/2839 - Loss: 2.0290\n",
      "Step 200/2839 - Loss: 1.4297\n",
      "Step 300/2839 - Loss: 1.1987\n",
      "Step 400/2839 - Loss: 1.0711\n",
      "Step 500/2839 - Loss: 0.9858\n",
      "Step 600/2839 - Loss: 0.9255\n",
      "Step 700/2839 - Loss: 0.8794\n",
      "Step 800/2839 - Loss: 0.8432\n",
      "Step 900/2839 - Loss: 0.8142\n",
      "Step 1000/2839 - Loss: 0.7882\n",
      "Step 1100/2839 - Loss: 0.7672\n",
      "Step 1200/2839 - Loss: 0.7486\n",
      "Step 1300/2839 - Loss: 0.7313\n",
      "Step 1400/2839 - Loss: 0.7168\n",
      "Step 1500/2839 - Loss: 0.7033\n",
      "Step 1600/2839 - Loss: 0.6910\n",
      "Step 1700/2839 - Loss: 0.6801\n",
      "Step 1800/2839 - Loss: 0.6702\n",
      "Step 1900/2839 - Loss: 0.6613\n",
      "Step 2000/2839 - Loss: 0.6526\n",
      "Step 2100/2839 - Loss: 0.6453\n",
      "Step 2200/2839 - Loss: 0.6385\n",
      "Step 2300/2839 - Loss: 0.6315\n",
      "Step 2400/2839 - Loss: 0.6254\n",
      "Step 2500/2839 - Loss: 0.6191\n",
      "Step 2600/2839 - Loss: 0.6138\n",
      "Step 2700/2839 - Loss: 0.6085\n",
      "Step 2800/2839 - Loss: 0.6033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 150, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 150, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This is Generated Text----------------> I\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 150, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This is Generated Text----------------> Y\n",
      " This is Generated Text----------------> N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 150, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This is Generated Text----------------> I\n",
      "Epoch 1 | Train Loss: 0.038\n",
      "Step 100/2839 - Loss: 0.4540\n",
      "Step 200/2839 - Loss: 0.4511\n",
      "Step 300/2839 - Loss: 0.4511\n",
      "Step 400/2839 - Loss: 0.4486\n",
      "Step 500/2839 - Loss: 0.4475\n",
      "Step 600/2839 - Loss: 0.4474\n",
      "Step 700/2839 - Loss: 0.4478\n",
      "Step 800/2839 - Loss: 0.4467\n",
      "Step 900/2839 - Loss: 0.4459\n",
      "Step 1000/2839 - Loss: 0.4448\n",
      "Step 1100/2839 - Loss: 0.4446\n",
      "Step 1200/2839 - Loss: 0.4442\n",
      "Step 1300/2839 - Loss: 0.4436\n",
      "Step 1400/2839 - Loss: 0.4424\n",
      "Step 1500/2839 - Loss: 0.4415\n",
      "Step 1600/2839 - Loss: 0.4406\n",
      "Step 1700/2839 - Loss: 0.4406\n",
      "Step 1800/2839 - Loss: 0.4400\n",
      "Step 1900/2839 - Loss: 0.4394\n",
      "Step 2000/2839 - Loss: 0.4386\n",
      "Step 2100/2839 - Loss: 0.4385\n",
      "Step 2200/2839 - Loss: 0.4377\n",
      "Step 2300/2839 - Loss: 0.4372\n",
      "Step 2400/2839 - Loss: 0.4366\n",
      "Step 2500/2839 - Loss: 0.4360\n",
      "Step 2600/2839 - Loss: 0.4354\n",
      "Step 2700/2839 - Loss: 0.4347\n",
      "Step 2800/2839 - Loss: 0.4340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 150, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 150, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This is Generated Text----------------> D\n",
      " This is Generated Text----------------> T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 150, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This is Generated Text----------------> C"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 150, but `max_length` is set to 100. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " This is Generated Text----------------> Y\n",
      "Epoch 2 | Train Loss: 0.027\n"
     ]
    }
   ],
   "source": [
    "train_dataset = QADataset(tokenizer,train_df)\n",
    "val_dataset = QADataset(tokenizer,val_df)\n",
    "\n",
    "config = GPT2Config.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2', config=config)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(2):\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    for step,batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**inputs, labels=inputs['input_ids'])\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        if (step + 1) % 100 == 0:\n",
    "            print(f\"Step {step + 1}/{len(train_loader)} - Loss: {train_loss / (step + 1):.4f}\")\n",
    "    train_loss /= len(train_dataset)\n",
    "    validate(model,tokenizer,val_loader)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fZ6bYOsWxqrK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iatvGSEO0yCS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04Ah2200K5mY"
   },
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M7sbGXCmK6T6",
    "outputId": "1da95c96-280b-4c99-a5d2-e6853e7f4d9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KD6A7cxLK62a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/content/drive/My Drive/nlp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I am also saving the optimizer state dict in case that I want to train the model for more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "WJa3mEw4K_8N"
   },
   "outputs": [],
   "source": [
    "torch.save({'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),}, '/content/drive/My Drive/nlp/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qMMmBc5lLGpF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRIVgXCGXjRe"
   },
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ujgEFmLXj4v",
    "outputId": "fd9a29d3-994f-42bb-a7ea-b4d3d9410526"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50260, 768)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "val_dataset = QADataset(tokenizer,val_df)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "config = GPT2Config.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2', config=config)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V24u_VyXK5cQ",
    "outputId": "cbcf6742-8e73-499a-f047-e6bdb9adb534"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50260, 768)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('model.pt',map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ZCTtHQeHp3QB"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zgbraralp3Lh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "132BL5Zd14GS"
   },
   "source": [
    "## For using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "41VFQAtQlCdi"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "@torch.no_grad()\n",
    "def validate(model, tokenizer,val_dl,prompt=\"Hi\"):\n",
    "    model.eval()\n",
    "    tokenized = tokenizer(prompt,return_tensors='pt')\n",
    "    X = tokenized[\"input_ids\"].to(device)\n",
    "    a = tokenized[\"attention_mask\"].to(device)\n",
    "    output = model.generate(X, attention_mask=a ,max_new_tokens=80)\n",
    "    output = tokenizer.decode(output[0],skip_special_tokens=True)\n",
    "    print(f'This is output----------> {output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The reason why the output is also showing the question is because in any generative model, it predicts the next \"tokens\" after a particular sequence, but this can be easily be taken care of to only show the output which is coming after the question has been asked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n3H-xWGlp3EZ",
    "outputId": "75ebd167-f506-408e-ad9a-903255460aa8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is output----------> can you suggest hotels?There are 5 hotels that match your criteria. Do you have a price range in mind?\n"
     ]
    }
   ],
   "source": [
    "validate(model,tokenizer,val_loader,prompt=\"can you suggest hotels?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qtK587VMoeRk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q5x4-CL-nS3u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H09x-Cn3nPyu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zJIQJ27unKvf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hf4C2KAXp3CJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9qA6iabep2_z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NNDfooC-p29h"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1F2IJXlep264"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G0VbJAJFQMdQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mtuw3s-UQOWT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KHC2NZTwQOT0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mD2D1hCxQOQC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p7WFLfblQON5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SElRrDCrQOLw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMb5A4L5QOI_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "abSQOochQMbQ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFGPT2DoubleHeadsModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = TFGPT2DoubleHeadsModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Add a [CLS] to the vocabulary (we should train it also!)\n",
    "num_added_tokens = tokenizer.add_special_tokens({\"cls_token\": \"[CLS]\"})\n",
    "\n",
    "embedding_layer = model.resize_token_embeddings(\n",
    "    len(tokenizer)\n",
    ")  # Update the model embeddings with the new vocabulary size\n",
    "\n",
    "choices = [\"Hello, my dog is cute [CLS]\", \"Hello, my cat is cute [CLS]\"]\n",
    "encoded_choices = [tokenizer.encode(s) for s in choices]\n",
    "cls_token_location = [tokens.index(tokenizer.cls_token_id) for tokens in encoded_choices]\n",
    "\n",
    "input_ids = tf.constant(encoded_choices)[None, :]  # Batch size: 1, number of choices: 2\n",
    "mc_token_ids = tf.constant([cls_token_location])  # Batch size: 1\n",
    "\n",
    "outputs = model(input_ids, mc_token_ids=mc_token_ids)\n",
    "lm_prediction_scores, mc_prediction_scores = outputs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vqh9YBkrQMZB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eF6etdunQMWw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VRFCNfUUQMUQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5WoyAqGQMR4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JTf_nwZcQMPx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cTJHfa_hQMNh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZWlnuHGQMLB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zrEvRX3uQMIw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JsRefxOPQMGQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0cpKHuT0p24o"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "25488d0f2abd4ca988c899ff347ab6b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2aeeaaaed9624e60907c221c4daccbdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a0abe88007344a080049fce14f5e9ca",
      "placeholder": "​",
      "style": "IPY_MODEL_4aabdd76e5c24520967107cd0c5fb519",
      "value": " 124/124 [00:00&lt;00:00, 1.67kB/s]"
     }
    },
    "3728fe249c8140cebcc54801f3ab2cd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4a2679e2032c4889a9e7c4043c2b9828": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4aabdd76e5c24520967107cd0c5fb519": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4d9f5d90cb454f0592bba9c9613e3ce2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8e8e01529dc941c9bf57cb3eae654952",
      "placeholder": "​",
      "style": "IPY_MODEL_9d01468b3d8048188096e7005ac89a1e",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "5ab5d2c0724646fda38f43227d719ade": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7a0abe88007344a080049fce14f5e9ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83edce4e80bc47c2a28f8e2eaeeaf08e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e8e01529dc941c9bf57cb3eae654952": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9205efdc3e714349ac0e5e36ba0d83dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a1e2d74f9b1e41d8903d08dc385e513e",
      "placeholder": "​",
      "style": "IPY_MODEL_f18a9f7e9ba24fde8cd1fa4449466e34",
      "value": " 548M/548M [00:03&lt;00:00, 163MB/s]"
     }
    },
    "97a4f1d1434945d0ab01136af628f009": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d01468b3d8048188096e7005ac89a1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9daece72701d40c79c2c8de34a09aa2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_af713c9c41f742e7b0b21417c49ef2ce",
       "IPY_MODEL_cea7d027cf6c4550b2a30a761655e754",
       "IPY_MODEL_2aeeaaaed9624e60907c221c4daccbdd"
      ],
      "layout": "IPY_MODEL_e0adcab743004f19893397a6132df2c6"
     }
    },
    "a1e2d74f9b1e41d8903d08dc385e513e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af713c9c41f742e7b0b21417c49ef2ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97a4f1d1434945d0ab01136af628f009",
      "placeholder": "​",
      "style": "IPY_MODEL_4a2679e2032c4889a9e7c4043c2b9828",
      "value": "Downloading (…)neration_config.json: 100%"
     }
    },
    "c35f1bee65d04727970442cf3b599fd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83edce4e80bc47c2a28f8e2eaeeaf08e",
      "max": 548118077,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5ab5d2c0724646fda38f43227d719ade",
      "value": 548118077
     }
    },
    "c85dfb2b4f0b40bc9e7fa136d4d687ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4d9f5d90cb454f0592bba9c9613e3ce2",
       "IPY_MODEL_c35f1bee65d04727970442cf3b599fd4",
       "IPY_MODEL_9205efdc3e714349ac0e5e36ba0d83dd"
      ],
      "layout": "IPY_MODEL_f48cc60833d64180b24c8d8a5bffd586"
     }
    },
    "cea7d027cf6c4550b2a30a761655e754": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_25488d0f2abd4ca988c899ff347ab6b8",
      "max": 124,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3728fe249c8140cebcc54801f3ab2cd5",
      "value": 124
     }
    },
    "e0adcab743004f19893397a6132df2c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f18a9f7e9ba24fde8cd1fa4449466e34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f48cc60833d64180b24c8d8a5bffd586": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
